\section{Introduction \& the idea}
DeepProbLog \cite{DBLP} can be used to incorporate logical predicates into a neural network model. Here, we try to compare a DeepProbLog model with a normal CNN by training it on a simple game of rock paper scissors. Testing if the DeepProbLog model has an advantage over the normal CNN is the goal of this experiment. By increasing the complexity of the game, which is done by adding 2 novel hand gestures lizard and spock, we are able to compare the effect it has on both models. What is important to analyse is how both models handle it and if the DeepProbLog model is more scalable. We believe that by incorporating the logical predicate, we give the model additional information about the rules of the game, which can result in a faster learning process compared to a CNN that does not receive these rules. The results are interesting to see, we are reporting how large of an advantage the DeepProbLog model can have over the default CNN. In general, DeepProbLog can be seen as an optimisation technique when there are rules available that can support the network.
